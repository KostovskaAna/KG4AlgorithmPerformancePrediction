{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ELA_taxonomy(KG):\n",
    "    KG.append(['diff_mean_02', 'is-a', 'disp'])\n",
    "    KG.append(['diff_mean_05', 'is-a', 'disp'])\n",
    "    KG.append(['diff_mean_10', 'is-a', 'disp'])\n",
    "    KG.append(['diff_mean_25', 'is-a', 'disp'])\n",
    "    KG.append(['diff_median_02', 'is-a', 'disp'])\n",
    "    KG.append(['diff_median_05', 'is-a', 'disp'])\n",
    "    KG.append(['diff_median_10', 'is-a', 'disp'])\n",
    "    KG.append(['diff_median_25', 'is-a', 'disp'])\n",
    "    KG.append(['dist_ratio.coeff_var', 'is-a', 'nbc'])\n",
    "    KG.append(['eps.max', 'is-a', 'ic'])\n",
    "    KG.append(['eps.ratio', 'is-a', 'ic'])\n",
    "    KG.append(['eps.s', 'is-a', 'ic'])\n",
    "    KG.append(['expl_var.cor_init', 'is-a', 'pca'])\n",
    "    KG.append(['expl_var.cor_x,', 'is-a', 'pca'])\n",
    "    KG.append(['expl_var.cov_init', 'is-a', 'pca'])\n",
    "    KG.append(['expl_var.cov_x', 'is-a', 'pca'])\n",
    "    KG.append(['expl_var_PC1.cor_init', 'is-a', 'pca'])\n",
    "    KG.append(['expl_var_PC1.cor_x', 'is-a', 'pca'])\n",
    "    KG.append(['expl_var_PC1.cov_init', 'is-a', 'pca'])\n",
    "    KG.append(['expl_var_PC1.cov_x', 'is-a', 'pca'])\n",
    "    KG.append(['h.max', 'is-a', 'ic'])\n",
    "    KG.append(['kurtosis', 'is-a', 'ela-distr'])\n",
    "    KG.append(['lin_simple.adj_r2', 'is-a', 'ela-meta'])\n",
    "    KG.append(['lin_simple.coef.max', 'is-a', 'ela-meta'])\n",
    "    KG.append(['lin_simple.coef.max_by_min', 'is-a', 'ela-meta'])\n",
    "    KG.append(['lin_simple.coef.min', 'is-a', 'ela-meta'])\n",
    "    KG.append(['lin_simple.intercept', 'is-a', 'ela-meta'])\n",
    "    KG.append(['lin_w_interact.adj_r2', 'is-a', 'ela-meta'])\n",
    "    KG.append(['m0', 'is-a', 'ic'])\n",
    "    KG.append(['nb_fitness.cor', 'is-a', 'nbc'])\n",
    "    KG.append(['nn_nb.cor', 'is-a', 'nbc'])\n",
    "    KG.append(['nn_nb.mean_ratio', 'is-a', 'nbc'])\n",
    "    KG.append(['nn_nb.sd_ratio', 'is-a', 'nbc'])\n",
    "    KG.append(['number_of_peaks', 'is-a', 'ela-distr'])\n",
    "    KG.append(['quad_simple.adj_r2', 'is-a', 'ela-meta'])\n",
    "    KG.append(['quad_simple.cond', 'is-a', 'ela-meta'])\n",
    "    KG.append(['quad_w_interact.adj_r2', 'is-a', 'ela-meta'])\n",
    "    KG.append(['ratio_mean_02', 'is-a', 'disp'])\n",
    "    KG.append(['ratio_mean_05', 'is-a', 'disp'])\n",
    "    KG.append(['ratio_mean_10', 'is-a', 'disp'])\n",
    "    KG.append(['ratio_mean_25', 'is-a', 'disp'])\n",
    "    KG.append(['ratio_median_02', 'is-a', 'disp'])\n",
    "    KG.append(['ratio_median_05', 'is-a', 'disp'])\n",
    "    KG.append(['ratio_median_10', 'is-a', 'disp'])\n",
    "    KG.append(['ratio_median_25', 'is-a', 'disp'])\n",
    "    KG.append(['skewness', 'is-a', 'ela-distr'])\n",
    "\n",
    "    KG.append(['disp', 'is-a', 'ELA_feature'])\n",
    "    KG.append(['ela-distr', 'is-a', 'ELA_feature'])\n",
    "    KG.append(['ela-meta', 'is-a', 'ELA_feature'])\n",
    "    KG.append(['ic', 'is-a', 'ELA_feature'])\n",
    "    KG.append(['nbc', 'is-a', 'ELA_feature'])\n",
    "    KG.append(['pca', 'is-a', 'ELA_feature'])\n",
    "\n",
    "    return KG\n",
    "\n",
    "def add_problem_taxonomy(KG):\n",
    "    problem_instance_array = []\n",
    "    for f in range(1,25):\n",
    "        if f >=1 and f<=5:\n",
    "            KG.append(['f'+str(f), 'is-a', 'separable'])\n",
    "        elif f >=6 and f<=9:\n",
    "            KG.append(['f'+str(f), 'is-a', 'low or moderate conditioning'])\n",
    "        elif f >=10 and f<=14:\n",
    "            KG.append(['f'+str(f), 'is-a', 'high conditioning and unimodal'])\n",
    "        elif f >=15 and f<=19:\n",
    "            KG.append(['f'+str(f), 'is-a', 'multi modal with adequate global structure'])\n",
    "        elif f >=19 and f<=24:\n",
    "            KG.append(['f'+str(f), 'is-a', 'multi modal with whit global structure'])\n",
    "\n",
    "        \n",
    "        for i in range(1,6):\n",
    "            KG.append(['f'+str(f)+'_i'+str(i), 'is-a', 'f'+str(f)])\n",
    "            problem_instance_array.append('f'+str(f)+'_i'+str(i))\n",
    "            \n",
    "    KG.append(['separable', 'is-a', 'benchmark_problem'])\n",
    "    KG.append(['low or moderate conditioning', 'is-a', 'benchmark_problem'])\n",
    "    KG.append(['high conditioning and unimodal', 'is-a', 'benchmark_problem'])\n",
    "    KG.append(['multi modal with adequate global structure', 'is-a', 'benchmark_problem'])\n",
    "    KG.append(['multi modal with whit global structure', 'is-a', 'benchmark_problem'])\n",
    "    \n",
    "    return KG\n",
    "\n",
    "def add_algo_conf_triples(KG, modules, df_grid, algo):\n",
    "    for module in modules:\n",
    "        module_values = df_grid[module]\n",
    "        module_indices = np.array(module_values.index)\n",
    "        module_values = np.array(module_values)\n",
    "        for module_index in module_indices:\n",
    "            mod_val = module_values[module_index]\n",
    "            if algo == 'modCMA':\n",
    "                if module == 'elitist':\n",
    "                    if mod_val == True:\n",
    "                        KG.append(['conf_'+str(module_index), 'elitist', 'True'])\n",
    "                    elif mod_val == False:\n",
    "                        KG.append(['conf_'+str(module_index), 'elitist', 'False'])\n",
    "                elif module == 'mirrored':\n",
    "                    if mod_val == 'Not':\n",
    "                        KG.append(['conf_'+str(module_index), 'mirrored', 'is-not-mirrored'])\n",
    "                    elif mod_val == 'mirrored':\n",
    "                        KG.append(['conf_'+str(module_index), 'mirrored', 'is-mirrored'])\n",
    "                    elif mod_val == 'mirrored pairwise':\n",
    "                        KG.append(['conf_'+str(module_index), 'mirrored', 'is-mirrored-pairwise'])\n",
    "                elif module == 'base_sampler':\n",
    "                    if mod_val == 'gaussian':\n",
    "                        KG.append(['conf_'+str(module_index), 'base-sampler', 'gaussian'])\n",
    "                    elif mod_val == 'halton':\n",
    "                        KG.append(['conf_'+str(module_index), 'base-sampler', 'halton'])\n",
    "                    elif mod_val == 'sobol':\n",
    "                        KG.append(['conf_'+str(module_index), 'base-sampler', 'sobol'])\n",
    "                elif module == 'weights_option':\n",
    "                    if mod_val == '1/2^lambda':\n",
    "                        KG.append(['conf_'+str(module_index), 'weights-option', '1/2^lambda'])\n",
    "                    elif mod_val == 'equal':\n",
    "                        KG.append(['conf_'+str(module_index), 'weights-option', 'equal'])\n",
    "                    elif mod_val == 'default':\n",
    "                        KG.append(['conf_'+str(module_index), 'weights-option', 'default'])\n",
    "                elif module == 'local_restart':\n",
    "                    if mod_val == 'Not':\n",
    "                        KG.append(['conf_'+str(module_index), 'local-restart', 'no-restart'])\n",
    "                    elif mod_val == 'IPOP':\n",
    "                        KG.append(['conf_'+str(module_index), 'local-restart', 'IPOP'])\n",
    "                    elif mod_val == 'BIPOP':\n",
    "                        KG.append(['conf_'+str(module_index), 'local-restart', 'BIPOP'])\n",
    "                elif module == 'step_size_adaptation':\n",
    "                    if mod_val == 'csa':\n",
    "                        KG.append(['conf_'+str(module_index), 'step-size-adaptation', 'csa'])\n",
    "                    elif mod_val == 'psr':\n",
    "                        KG.append(['conf_'+str(module_index), 'step-size-adaptation', 'psr'])\n",
    "            elif algo == 'modDE':\n",
    "                if module == 'mutation_base':\n",
    "                    if mod_val == \"rand\":\n",
    "                        KG.append(['conf_'+str(module_index), 'mutation-base', 'rand-mutation-base'])\n",
    "                    elif mod_val == \"best\":\n",
    "                        KG.append(['conf_'+str(module_index), 'mutation-base', 'best-mutation-base'])\n",
    "                    elif mod_val == 'target':\n",
    "                        KG.append(['conf_'+str(module_index), 'mutation-base', 'target-mutation-base'])\n",
    "                elif module == 'mutation_reference':\n",
    "                    if mod_val == \"Not\":\n",
    "                        KG.append(['conf_'+str(module_index), 'mutation-reference', 'No-mutation-reference'])\n",
    "                    elif mod_val == \"pbest\":\n",
    "                        KG.append(['conf_'+str(module_index), 'mutation-reference', 'pbest-mutation-reference'])\n",
    "                    elif mod_val == \"best\":\n",
    "                        KG.append(['conf_'+str(module_index), 'mutation-reference', 'best-mutation-reference'])\n",
    "                    elif mod_val == \"rand\":\n",
    "                        KG.append(['conf_'+str(module_index), 'mutation-reference', 'rand-mutation-reference'])\n",
    "                elif module == 'mutation_n_comps':\n",
    "                    if mod_val == 1:\n",
    "                        KG.append(['conf_'+str(module_index), 'mutation-n-comps', '1-comps'])\n",
    "                    elif mod_val == 2:\n",
    "                        KG.append(['conf_'+str(module_index), 'mutation-n-comps', '2-comps'])\n",
    "                elif module == 'use_archive':\n",
    "                    if mod_val == True:\n",
    "                        KG.append(['conf_'+str(module_index), 'use_archive', 'archive-true'])\n",
    "                    elif mod_val == False:\n",
    "                         KG.append(['conf_'+str(module_index), 'use_archive', 'archive-false'])\n",
    "                elif module == 'crossover':\n",
    "                    if mod_val == \"bin\":\n",
    "                        KG.append(['conf_'+str(module_index), 'crossover', 'bin-crossover'])\n",
    "                    elif mod_val == \"exp\":\n",
    "                        KG.append(['conf_'+str(module_index), 'crossover', 'exp-crossover'])\n",
    "                elif module == 'adaptation_method':\n",
    "                    if mod_val == \"Not\":\n",
    "                        KG.append(['conf_'+str(module_index), 'adaptation-method', 'no-adaptation-method'])\n",
    "                    elif mod_val == \"shade\":\n",
    "                        KG.append(['conf_'+str(module_index), 'adaptation-method', 'shade-adaptation-method'])\n",
    "                    elif mod_val == \"jDE\":\n",
    "                        KG.append(['conf_'+str(module_index), 'adaptation-method', 'jDE-adaptation-method'])\n",
    "                elif module == \"lpsr\":\n",
    "                    if mod_val == True:\n",
    "                        KG.append(['conf_'+str(module_index), 'lpsr', 'lpsr-true'])\n",
    "                    elif mod_val == False: \n",
    "                        KG.append(['conf_'+str(module_index), 'lpsr', 'lpsr-false'])\n",
    "    return KG\n",
    "\n",
    "def add_ELA_features_values(KG, dim):\n",
    "    df_ELA = pd.read_csv(f'../DATA/ELA_data/ELA_Sobol_100D_{dim}dim_discretized.csv', index_col=0)\n",
    "    for ELA_feature in df_ELA.columns:\n",
    "        ELA_feature_values = df_ELA[ELA_feature]\n",
    "        ELA_feature_indices = np.array(ELA_feature_values.index)\n",
    "        for ELA_feature_value_index in ELA_feature_indices:\n",
    "            ELA_feature_val = str(ELA_feature_values[ELA_feature_value_index])\n",
    "            KG.append([ELA_feature_value_index, ELA_feature, ELA_feature_val])\n",
    "\n",
    "    return KG\n",
    "\n",
    "def add_performance_triples(KG_all_links, algo, dim, budget, fixed_target, conf_num):\n",
    "    for conf_id in range(0, conf_num):\n",
    "        df_conf = pd.read_csv(f'../DATA/processed_data_runs/{algo}/dim_{dim}_budget_{budget}_conf_{conf_id}_{dim}D.csv', index_col=0)\n",
    "        df_conf['f_i'] = df_conf.apply(lambda row: 'f'+str(int(row['function']))+'_i'+str(int(row['instance'])), axis=1)\n",
    "        df_conf = df_conf.set_index('f_i')    \n",
    "        df_conf['target'] = df_conf.apply(lambda row: np.median(row[-10:]), axis=1)\n",
    "\n",
    "        targets = df_conf['target']\n",
    "        df_conf['solves'] = df_conf.apply(lambda row: (True if row.target<fixed_target else False), axis=1)\n",
    "        for target_val_idx in df_conf['solves'].index:\n",
    "            is_solved = df_conf['solves'][target_val_idx]\n",
    "            KG_all_links.append(['conf_'+str(conf_id), 'solved' if is_solved else 'not-solved', target_val_idx])\n",
    "    return KG_all_links\n",
    "\n",
    "def get_KG_data(dim, budget, fixed_target, algo, conf_num):\n",
    "    df_grid = pd.read_csv(f\"../DATA/{algo}_dt_grid.csv\", index_col=0)\n",
    "    df_grid = df_grid.replace({np.nan: 'Not'})\n",
    "    modules = df_grid.columns \n",
    "\n",
    "    KG =[]\n",
    "    KG_all_links = []\n",
    "\n",
    "    # add algorithm configuration tripples\n",
    "    KG = add_algo_conf_triples(KG, modules, df_grid, algo)\n",
    "    # add problem instance is-a relations\n",
    "    KG = add_problem_taxonomy(KG)\n",
    "    # add ELA feature values \n",
    "    KG = add_ELA_features_values(KG, dim)\n",
    "    # add ELA is-a relations\n",
    "    KG = add_ELA_taxonomy(KG)\n",
    "    #add solved and not-solved performance triples\n",
    "    KG_all_links = add_performance_triples(KG_all_links, algo, dim, budget, fixed_target, conf_num)\n",
    "    # create train-val-test split (60%, 20%, 20%)\n",
    "    df_all_links = pd.DataFrame(KG_all_links, columns=['conf', 'solves', 'instance'])\n",
    "    test_size = int(0.2*len(df_all_links))\n",
    "\n",
    "    df_train, df_test = train_test_split(df_all_links, test_size=test_size, stratify = df_all_links[['solves']], random_state=42)\n",
    "    df_train, df_val =  train_test_split(df_train, test_size=test_size, stratify = df_train[['solves']], random_state=42)\n",
    "    KG_train_links = df_train.values.tolist()\n",
    "    KG_train = KG_train_links + KG \n",
    "    KG_val = df_val.values.tolist()\n",
    "    KG_test = df_test.values.tolist()\n",
    "    KG_all_links = df_all_links.values.tolist()\n",
    "    \n",
    "    np.save(f'../DATA/KG/{algo}/KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_train.npy', KG_train)\n",
    "    np.save(f'../DATA/KG/{algo}/KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_val.npy', KG_val)\n",
    "    np.save(f'../DATA/KG/{algo}/KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_test.npy', KG_test)\n",
    "    np.save(f'../DATA/KG/{algo}/KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_all_links.npy', KG_all_links)\n",
    "    np.save(f'../DATA/KG/{algo}/KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_train_links.npy', KG_train_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo in ['modCMA', 'modDE']:\n",
    "    conf_num = 324 if algo == 'modCMA' else 576\n",
    "    for dim in [5, 30]:\n",
    "        for budget in [2000, 5000, 10000, 50000]:\n",
    "            targets = [1, 0.1, 0.001] if dim == 5 else [10, 1, 0.1] \n",
    "            for fixed_target in targets:\n",
    "                get_KG_data(dim, budget, fixed_target, algo, conf_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KG_data_remove_random_problems_confs(dim, budget, fixed_target, algo, conf_num, removal_mode):\n",
    "\n",
    "    df_grid = pd.read_csv(f\"../DATA/{algo}_dt_grid.csv\", index_col=0)\n",
    "    df_grid = df_grid.replace({np.nan: 'Not'})\n",
    "    modules = df_grid.columns \n",
    "\n",
    "    KG = []\n",
    "    KG_all_links = []\n",
    "\n",
    "    # add algorithm configuration tripples\n",
    "    KG = add_algo_conf_triples(KG, modules, df_grid, algo)\n",
    "    # add problem instance is-a relations\n",
    "    KG = add_problem_taxonomy(KG)\n",
    "    # add ELA feature values \n",
    "    KG = add_ELA_features_values(KG, dim)\n",
    "    # add ELA is-a relations\n",
    "    KG = add_ELA_taxonomy(KG)\n",
    "    #add solved and not-solved performance triples\n",
    "    KG_all_links = add_performance_triples(KG_all_links, algo, dim, budget, fixed_target, conf_num)\n",
    "    df_all_links = pd.DataFrame(KG_all_links, columns=['conf', 'solves', 'instance'])\n",
    "    \n",
    "    if(removal_mode == 'problem'):\n",
    "        for i in range(1, 6):\n",
    "            test_problem_id = 'f\\d+_i'+str(i)\n",
    "            df_test = df_all_links[df_all_links.instance.str.contains(fr'\\b{test_problem_id}\\b', regex=True)]\n",
    "            df_train = df_all_links[~df_all_links.instance.str.contains(fr'\\b{test_problem_id}\\b', regex=True)]\n",
    "            val_problem_id = i-1 if i > 1 else 5\n",
    "            val_problem_id = 'f\\d+_i'+str(val_problem_id)\n",
    "            df_val = df_train[df_train.instance.str.contains(fr'\\b{val_problem_id}\\b', regex=True)]\n",
    "            df_train = df_train[~df_train.instance.str.contains(fr'\\b{val_problem_id}\\b', regex=True)]\n",
    "            KG_train_links = df_train.values.tolist()\n",
    "            KG_train = KG_train_links + KG \n",
    "            KG_val = df_val.values.tolist()\n",
    "            KG_test = df_test.values.tolist()\n",
    "            KG_all_links = df_all_links.values.tolist()\n",
    "            \n",
    "            np.save(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{i}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_train.npy', KG_train)\n",
    "            np.save(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{i}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_val.npy', KG_val)\n",
    "            np.save(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{i}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_test.npy', KG_test)\n",
    "            np.save(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{i}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_all_links.npy', KG_all_links)\n",
    "            np.save(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{i}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_train_links.npy', KG_train_links)\n",
    "\n",
    "    elif(removal_mode == 'config'):\n",
    "        import random\n",
    "        random_seeds = [1, 2, 3, 4, 5]\n",
    "        confs = ['conf_'+str(c) for c in range(0, conf_num)]\n",
    "        for random_seed in random_seeds:\n",
    "            random.seed(random_seed)\n",
    "            test_configs = random.sample(confs, int(len(confs)*0.2))\n",
    "            train_configs = [ele for ele in confs if ele not in test_configs]\n",
    "            val_configs = random.sample(train_configs, int(len(confs)*0.2))\n",
    "            train_configs = [ele for ele in confs if ele not in test_configs]\n",
    "            \n",
    "            df_train = df_all_links[df_all_links.conf.isin(train_configs)]\n",
    "            df_val = df_all_links[df_all_links.conf.isin(val_configs)]\n",
    "            df_test = df_all_links[df_all_links.conf.isin(test_configs)]\n",
    "\n",
    "            KG_train_links = df_train.values.tolist()\n",
    "            KG_train = KG_train_links + KG \n",
    "            KG_val = df_val.values.tolist()\n",
    "            KG_test = df_test.values.tolist()\n",
    "            KG_all_links = df_all_links.values.tolist()\n",
    "\n",
    "            np.save(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{random_seed}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_train.npy', KG_train)\n",
    "            np.save(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{random_seed}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_val.npy', KG_val)\n",
    "            np.save(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{random_seed}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_test.npy', KG_test)\n",
    "            np.save(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{random_seed}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_all_links.npy', KG_all_links)\n",
    "            np.save(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{random_seed}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_train_links.npy', KG_train_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_target = 0.1\n",
    "algo = 'modDE'\n",
    "conf_num = 324 if algo == 'modCMA' else 576\n",
    "dim = 5\n",
    "for budget in [2000, 5000, 10000, 50000]:\n",
    "    for removal_mode in ['problem', 'config']:\n",
    "        get_KG_data_remove_random_problems_confs(dim, budget, fixed_target, algo, conf_num, removal_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check \n",
    "import numpy as np \n",
    "\n",
    "algo = \"modCMA\"\n",
    "removal_mode = \"problem\"\n",
    "random_seed = 5\n",
    "dim = 5\n",
    "budget = 5000\n",
    "fixed_target = 0.1\n",
    "KG_train_links = np.load(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{random_seed}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_train_links.npy')\n",
    "KG_train = np.load(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{random_seed}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_train.npy')\n",
    "KG_val = np.load(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{random_seed}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_val.npy')\n",
    "KG_test = np.load(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{random_seed}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_test.npy')\n",
    "KG_train_test_links = np.load(f'../DATA/KG_random_subset/{algo}/{removal_mode}/rand_{random_seed}_KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_all_links.npy')\n",
    "\n",
    "\n",
    "# print(len(KG_train_links))\n",
    "# print(len(KG_val))\n",
    "# print(len(KG_test))\n",
    "# print(len(KG_train))\n",
    "# print(len(KG_train_test_links))\n",
    "\n",
    "print(KG_train_links)\n",
    "print(KG_val)\n",
    "print(KG_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_counts(KG):\n",
    "    solved = 0\n",
    "    not_solved = 0\n",
    "    for t in KG:\n",
    "        if t[1] == 'solved':\n",
    "            solved +=1\n",
    "        else: \n",
    "            not_solved += 1\n",
    "    return solved, not_solved\n",
    "\n",
    "def get_ratios_solved(algo, dims, targets, budgets):\n",
    "    for dim in dims:\n",
    "        data = []\n",
    "        for fixed_target in targets:\n",
    "            arr = [fixed_target]\n",
    "            for budget in budgets:\n",
    "                KG_train = np.load(f'../DATA/KG/{algo}/KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_train_links.npy')\n",
    "                KG_val = np.load(f'../DATA/KG/{algo}/KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_val.npy')\n",
    "                KG_test = np.load(f'../DATA/KG/{algo}/KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_test.npy')\n",
    "                KG_all_links = np.load(f'../DATA/KG/{algo}/KG_dim_{dim}_budget_{budget}_target_{fixed_target:.5f}_all_links.npy')\n",
    "                solved_train, not_solved_train = get_triplet_counts(KG_train)\n",
    "                perc_train = solved_train/(solved_train+not_solved_train)\n",
    "                solved_val, not_solved_val = get_triplet_counts(KG_val)\n",
    "                perc_val = solved_val/(solved_val+not_solved_val)\n",
    "                solved_test, not_solved_test = get_triplet_counts(KG_test)\n",
    "                perc_test = solved_test/(solved_test+not_solved_test)\n",
    "                solved_all_links, not_solved_all_links = get_triplet_counts(KG_all_links)\n",
    "                perc_all_links = solved_all_links/(solved_all_links+not_solved_all_links)\n",
    "                # print(f'solved_all = {solved_all_links}, not_solved_all = {not_solved_all_links}, sum = {solved_all_links+not_solved_all_links}, perc = {perc_all_links}')\n",
    "                # print(f'solved_train = {solved_train}, not_solved_train = {not_solved_train}, sum = {solved_train+not_solved_train}, perc = {perc_train}')\n",
    "                # print(f'solved_val = {solved_val}, not_solved_vl = {not_solved_val}, sum = {solved_val+not_solved_val}, perc = {perc_val}')\n",
    "                # print(f'solved_test = {solved_test}, not_solved_test = {not_solved_test}, sum = {solved_test+not_solved_test}, perc = {perc_test}')\n",
    "                arr.append(f'{perc_all_links:.3f}')\n",
    "            data.append(arr)\n",
    "        df = pd.DataFrame(data=data, columns=['tar', '2000', '5000', '10000', '50000'])\n",
    "        print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tar   2000   5000  10000  50000\n",
      "0  1.000  0.629  0.682  0.713  0.789\n",
      "1  0.100  0.468  0.541  0.571  0.637\n",
      "2  0.001  0.369  0.478  0.507  0.559\n"
     ]
    }
   ],
   "source": [
    "get_ratios_solved('modCMA', [5], [1, 0.1, 0.001], [2000, 5000, 10000, 50000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ampligraph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57a4bf9b71c8e81dd0d84a354b467139dac349de803c45104f2f9630359e6221"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
